{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission Instructions\n",
    "\n",
    "Just fill in the markdown and code cells below with your arguments and functions, and run the Python lines given. Make sure the notebook works fine by executing `Kernel/Restart & Run All`.\n",
    "  \n",
    "Once the notebook is ready,\n",
    "1. Create a folder named `afi_last_name1_last_name2` with the team's last names.\n",
    "\n",
    "2. Put in that folder:\n",
    "\n",
    "* a file `mp_afi_last_name1_last_name2.ipynb` with the cells below completed. Make sure it works by executing Kernel/Restart & Run All.\n",
    "* a file `mp_afi_last_name1_last_name2.html` with an html rendering of the previous .ipynb file (just apply File / Download as HTML after a correct run of Kernel/Restart & Run All).\n",
    "* a file `mp_afi_last_name1_last_name2.pdf` with a pdf print of the html file **without any code**.\n",
    "\n",
    "3. Compress the folder to a `afi_last_name1_last_name2.7z` 7z (or zip) file.\n",
    "\n",
    "**Very important!!!**\n",
    "\n",
    "Make sure you follow the file naming conventions above; the miniproject won't be graded until that is so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations in notebook writing\n",
    "\n",
    "Notebooks are a great tool for data and model exploration. But in that process a lot of Python garbage can get into them as a consequence of the trial and error process.\n",
    "\n",
    "But once these tasks are done and one arrives to final ideas and insights on the problem under study, the notebook should be **thoroughly cleaned** and the notebook should **concentrate on the insights and conclussions** without, of course, throwing away the good work done.\n",
    "\n",
    "Below there are a few guidelines about this.\n",
    "\n",
    "* Put the useful bits of your code as functions on a **Python module** (plus script, if needed) that is imported at the notebook's beginning. \n",
    "* Of course that module should be **properly documented** and **formatted** (try to learn about PEP 8 if you are going to write a lot of Python).\n",
    "* Leave in the notebook **as little code as possible**, ideally one- or two-line cells calling a function, plotting results or so on.\n",
    "* **Avoid boilerplate code**. If needed, put it in a module.\n",
    "* Put on the notebook some way to **hide/display the code** (as shown below).\n",
    "* The displayed information **should be just that, informative**. So forget about large tables, long output cells, dataframe or array displays and so on.\n",
    "* Emphasize **insights and conclusions**, using as much markdown as needed to clarifiy and explain them.\n",
    "* Make sure that **number cells consecutively starting at 1.**\n",
    "* And, of course, make sure that **there are no errors left**. To avoid these last pitfalls, run `Kernel\\Restart Kernel and Run All Cells`.\n",
    "\n",
    "And notice that whoever reads your notebook is likely to toggle off your code and consider just the markdown cells. Because of this, once you feel that your notebook is finished,\n",
    "* let it rest for one day, \n",
    "* then open it up, toggle off the code \n",
    "* and read it to check **whether it makes sense to you**.\n",
    "\n",
    "If this is not the case, **the notebook is NOT finished!!!**\n",
    "\n",
    "Following these rules you are much more likely to get good grades at school (and possibly also larger bonuses at work)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT AND JUST IN CASE: before turning in your work, please REMOVE FROM IT THE PREVIOUS TWO CELLS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<script>code_show=true; \n",
       "\n",
       "function code_toggle() {\n",
       "    if (code_show){\n",
       "    $('div.input').hide();\n",
       "    } else {\n",
       "    $('div.input').show();\n",
       "    }\n",
       "    code_show = !code_show\n",
       "} \n",
       "\n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to show or hide your raw code.\"></form>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''\n",
    "<script>code_show=true; \n",
    "\n",
    "function code_toggle() {\n",
    "    if (code_show){\n",
    "    $('div.input').hide();\n",
    "    } else {\n",
    "    $('div.input').show();\n",
    "    }\n",
    "    code_show = !code_show\n",
    "} \n",
    "\n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to show or hide your raw code.\"></form>\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wind Energy Prediction\n",
    "We want to predict the wind energy production on a farm using wind speed and direction information.\n",
    "\n",
    "The aim of this wind power forecasting problem is to predict the wind power generation 24 h ahead for a wind farm in Australia.\n",
    "\n",
    "Attribute Information:\n",
    "The features include forecasts of the projections of the wind vector on the west-east (U) and south-north (V) axes,at two heights, 10 and 100 m above ground level, plus the corresponding absolute wind speeds.\n",
    "\n",
    "Data for approximate a **nine month period** are given in a csv file with headers\n",
    "\n",
    "`TIMESTAMP,TARGETVAR,U10,V10,U100,V100,v10,v100`\n",
    "\n",
    "where\n",
    "\n",
    "* TIMESTAMP contains day/hour information.\n",
    "* TARGETVAR is the wind energy production normalized to a [0, 100] range.\n",
    "* U10,V10,U100,V100 are the U and V wind components in m/s at heights 10 and 100.\n",
    "* v10,v100 are the absolute wind speeds in m/s at heights 10 and 100.\n",
    "\n",
    "The dataset we will use is an adaptation of those available in the Kaggle page https://www.kaggle.com/c/GEF2012-wind-forecasting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, KFold, GridSearchCV\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "We load the csv file using its first column as a `datetime` index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['U10', 'V10', 'U100', 'V100', 'v10', 'v100'], dtype='object')\n",
      "nFilas: 6576\tnColumnas: 7\n",
      "\n",
      "Columnas:\t ['U10' 'V10' 'U100' 'V100' 'v10' 'v100' 'target']\n"
     ]
    }
   ],
   "source": [
    "df_0 = pd.read_csv('..\\\\w_e.csv', index_col=0, parse_dates=True)\n",
    "l_vars = df_0.columns[1 : ]\n",
    "print(l_vars)\n",
    "df = df_0[l_vars]\n",
    "df['target'] = df_0['TARGETVAR']\n",
    "\n",
    "print (\"nFilas: %d\\tnColumnas: %d\\n\" % (df.shape[0], df.shape[1]) )\n",
    "print (\"Columnas:\\t\", np.array(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2012-01-01 01:00:00', '2012-01-01 02:00:00',\n",
       "               '2012-01-01 03:00:00', '2012-01-01 04:00:00',\n",
       "               '2012-01-01 05:00:00', '2012-01-01 06:00:00',\n",
       "               '2012-01-01 07:00:00', '2012-01-01 08:00:00',\n",
       "               '2012-01-01 09:00:00', '2012-01-01 10:00:00',\n",
       "               ...\n",
       "               '2012-09-30 15:00:00', '2012-09-30 16:00:00',\n",
       "               '2012-09-30 17:00:00', '2012-09-30 18:00:00',\n",
       "               '2012-09-30 19:00:00', '2012-09-30 20:00:00',\n",
       "               '2012-09-30 21:00:00', '2012-09-30 22:00:00',\n",
       "               '2012-09-30 23:00:00', '2012-10-01 00:00:00'],\n",
       "              dtype='datetime64[ns]', name='TIMESTAMP', length=6576, freq=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration, Visualization and Correlations\n",
    "\n",
    "* Compute descriptive statistics.\n",
    "* Draw boxplots, pairplots and histograms.\n",
    "* Compute and present correlations. \n",
    "\n",
    "Give your comments and conclusions after each step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms and scatterplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLPRegressor\n",
    "\n",
    "Perform a CV MLPR estimation of a pipelined MLPR over three folds over the entire sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing GridSearchCV results\n",
    "\n",
    "Check the adequacy of the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the MLPR model\n",
    "\n",
    "Do it over the entire dataset using `cross_val_predict`, get the CV MAE and draw the appropriate plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Residual histograms and relationship with targets\n",
    "\n",
    "Show and discuss them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SV Regressor\n",
    "\n",
    "Repeat the previous steps with an SVR model with the same structure.\n",
    "\n",
    "We will work with Gaussian kernels, so we have to set two hyperparameters, `C, gamma` plus the `epsilon` insensitivity. We have to explore **three** hyperparameters, so search times may increase considerably.  \n",
    "To shorten fit times we downsample the original data to values every three hours. You can use for this Pandas methods such as `resample, asfreq` and `dropna`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLPR and SVR comparison\n",
    "\n",
    "Compare them and draw the appropriate conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to improve the estimator\n",
    "\n",
    "Me may try to improve the MLPR and SVR results by enlarging the features set with the **square and cube powers of the absolute velocities**.\n",
    "\n",
    "Redo the previous MLPR and SVR analysis and conclusions over the enlarged dataset with the same analysis structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLPR model over enlarged features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions on the enlarged MLPR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR model over enlarged features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions on the enlarged SVR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final conclusions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
