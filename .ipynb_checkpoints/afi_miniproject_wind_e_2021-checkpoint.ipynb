{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission Instructions\n",
    "\n",
    "Just fill in the markdown and code cells below with your arguments and functions, and run the Python lines given. Make sure the notebook works fine by executing `Kernel/Restart & Run All`.\n",
    "  \n",
    "Once the notebook is ready,\n",
    "1. Create a folder named `ftdl_last_name1_last_name2` with the team's last names.\n",
    "\n",
    "2. Put in that folder:\n",
    "\n",
    "* a file `mp_ftdl_last_name1_last_name2.ipynb` with the cells below completed. Make sure it works by executing Kernel/Restart & Run All.\n",
    "* a file `mp_ftdl_last_name1_last_name2.html` with an html rendering of the previous .ipynb file (just apply File / Download as HTML after a correct run of Kernel/Restart & Run All).\n",
    "* a file `mp_ftdl_last_name1_last_name2.pdf` with a pdf print of the html file **without any code**.\n",
    "\n",
    "3. Compress the folder to a `ftdl_last_name1_last_name2.7z` 7z (or zip) file.\n",
    "\n",
    "**Very important!!!**\n",
    "\n",
    "Make sure you follow the file naming conventions above; the miniproject won't be graded until that is so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations in notebook writing\n",
    "\n",
    "Notebooks are a great tool for data and model exploration. But in that process a lot of Python garbage can get into them as a consequence of the trial and error process.\n",
    "\n",
    "But once these tasks are done and one arrives to final ideas and insights on the problem under study, the notebook should be **thoroughly cleaned** and the notebook should **concentrate on the insights and conclussions** without, of course, throwing away the good work done.\n",
    "\n",
    "Below there are a few guidelines about this.\n",
    "\n",
    "* Put the useful bits of your code as functions on a **Python module** (plus script, if needed) that is imported at the notebook's beginning. \n",
    "* Of course that module should be **properly documented** and **formatted** (try to learn about PEP 8 if you are going to write a lot of Python).\n",
    "* Leave in the notebook **as little code as possible**, ideally one- or two-line cells calling a function, plotting results or so on.\n",
    "* **Avoid boilerplate code**. If needed, put it in a module.\n",
    "* Put on the notebook some way to **hide/display the code** (as shown below).\n",
    "* The displayed information **should be just that, informative**. So forget about large tables, long output cells, dataframe or array displays and so on.\n",
    "* Emphasize **insights and conclusions**, using as much markdown as needed to clarifiy and explain them.\n",
    "* Make sure that **number cells consecutively starting at 1.**\n",
    "* And, of course, make sure that **there are no errors left**. To avoid these last pitfalls, run `Kernel\\Restart Kernel and Run All Cells`.\n",
    "\n",
    "And notice that whoever reads your notebook is likely to toggle off your code and consider just the markdown cells. Because of this, once you feel that your notebook is finished,\n",
    "* let it rest for one day, \n",
    "* then open it up, toggle off the code \n",
    "* and read it to check **whether it makes sense to you**.\n",
    "\n",
    "If this is not the case, **the notebook is NOT finished!!!**\n",
    "\n",
    "Following these rules you are much more likely to get good grades at school (and possibly also larger bonuses at work)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT AND JUST IN CASE: before turning in your work, please REMOVE FROM IT THE PREVIOUS TWO CELLS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''\n",
    "<script>code_show=true; \n",
    "\n",
    "function code_toggle() {\n",
    "    if (code_show){\n",
    "    $('div.input').hide();\n",
    "    } else {\n",
    "    $('div.input').show();\n",
    "    }\n",
    "    code_show = !code_show\n",
    "} \n",
    "\n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to show or hide your raw code.\"></form>\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wind Energy Prediction\n",
    "We want to predict the wind energy production on a farm using wind speed and direction information.\n",
    "\n",
    "The aim of this wind power forecasting problem is to predict the wind power generation 24 h ahead for a wind farm in Australia.\n",
    "\n",
    "Attribute Information:\n",
    "The features include forecasts of the projections of the wind vector on the west-east (U) and south-north (V) axes,at two heights, 10 and 100 m above ground level, plus the corresponding absolute wind speeds.\n",
    "\n",
    "Data for a 10 month period are given in a csv file with headers\n",
    "\n",
    "`TIMESTAMP,TARGETVAR,U10,V10,U100,V100,v10,v100`\n",
    "\n",
    "where\n",
    "\n",
    "* TIMESTAMP contains day/hour information.\n",
    "* TARGETVAR is the wind energy production normalized to a [0, 100] range.\n",
    "* U10,V10,U100,V100 are the U and V wind components in m/s at heights 10 and 100.\n",
    "* v10,v100 are the absolute wind speeds in m/s at heights 10 and 100.\n",
    "\n",
    "The dataset we will use is an adaptation of those available in the Kaggle page https://www.kaggle.com/c/GEF2012-wind-forecasting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, KFold, GridSearchCV\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "The dataset is preloaded in the sciki-learn library. As it is shown in the next output the dataset contains 6576 observations and 7 variables, including the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_0 = pd.read_csv('.\\w_e.csv', index_col=0, parse_dates=True)\n",
    "l_vars = df_0.columns[1 : ]\n",
    "print(l_vars)\n",
    "df = df_0[l_vars]\n",
    "df['target'] = df_0['TARGETVAR']\n",
    "\n",
    "print (\"nFilas: %d\\tnColumnas: %d\\n\" % (df.shape[0], df.shape[1]) )\n",
    "print (\"Columnas:\\t\", np.array(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration, Visualization and Correlations\n",
    "\n",
    "In this section, we will present a descriptive analysis over the entire dataset to know the nature of data.\n",
    "\n",
    "* Compute descriptive statistics.\n",
    "* Draw boxplots, pairplots and histograms.\n",
    "* Compute and present correlations. \n",
    "\n",
    "#TODO: Give your comments and conclusions after each step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive analysis\n",
    "\n",
    "We first showed a sample of data that allows us to know the format of data. We can see that data can be seen as a timeseries, because each observation belongs to a different instant time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, we show a descriptive analysis of all variables in the dataset. The count suggests that there are not missing values in our dataset because all variables have the same number of values. In addition, the quartiles metrics show that there is no rextremely rare values and value ranges appear to be reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe().round(decimals=2).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we are going to check the existence of outliers in each of the variables using boxplots. The data has been normalized in order to have uniform ranges in the graphics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized = (df - df.mean()) / df.std() \n",
    "\n",
    "plt.figure( figsize=(8, 5))\n",
    "sns.set_style(\"white\")\n",
    "bx_plot = sns.boxplot(data=df_normalized)\n",
    "plt.title(\"wind energy boxplots\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the figure above, the variables *v10* and *v100* are the ones with more outliers, points past the main lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms and scatterplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vars_to_show = 6 \n",
    "pair_plot = sns.pairplot(df[list(l_vars)[:num_vars_to_show] + ['target']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that there are no variables which have a linear relationship with the target. However, there is a clearly linear relationship bethween some of the variables. For intance, between v10 and v100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, it is shown the correlation matrix which helps us determine the variables that are linearly correlated. As it was said before, the variable *v10* and *v100* are highly correlated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.corr().round(decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_colors = 13\n",
    "cMap = plt.cm.get_cmap(\"bwr\",lut=n_colors ) \n",
    "\n",
    "fig = plt.figure( figsize=(10, 8))\n",
    "plt.title('wind energy correlations')\n",
    "h_map = sns.heatmap(df.corr().values, \n",
    "                    vmin=-1., vmax=1., \n",
    "                    cmap=cMap,\n",
    "                    annot=True,\n",
    "                    xticklabels=list(df.columns),\n",
    "                    yticklabels=list(df.columns))\n",
    "plt.xticks(rotation=90) \n",
    "\n",
    "cbar = h_map.collections[0].colorbar\n",
    "l_ticks = [k/10. for k in range(-8, 9, 2)]\n",
    "cbar.set_ticks(l_ticks)\n",
    "\n",
    "bottom, top = h_map.get_ylim()\n",
    "h_map.set_ylim(bottom + 0.5, top - 0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO highly correlated variables... It would be ... to eliminate one of the correlated variables because \n",
    "\n",
    "# Poner la parte de que no es invertible si hay variables altamente correlacionadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLPRegressor\n",
    "\n",
    "Perform a CV MLPR estimation of a pipelined MLPR over three folds over the entire sample.\n",
    "\n",
    "We perform a CV MLPRegressor using GridSearch to optimize hyperparameters. Initially, we selected as optimizable params the alpha, the hidden layer sizes and the maximum number of iterations. A first search was executed taking into account these three parameters, however, it was seen that the maximum number of iterations do not has a direct impact on results and it delayed the training stage, so we decide to fix it to 10000 iterations, which was the best hyperparameter found, and re-executed the search algorithm taking into account just the other two: alpha and hidden layer size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "\n",
    "x = sc.fit_transform(df[l_vars])\n",
    "y = df[['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USAMOS KFOLD CV\n",
    "n_folds = 3\n",
    "kf = KFold(n_folds, shuffle=False)\n",
    "\n",
    "mlpr_kf =  MLPRegressor(activation='relu', \n",
    "                     solver='lbfgs', \n",
    "                     early_stopping=True,\n",
    "                     tol=1.e-3, \n",
    "                     max_iter=10000)\n",
    "\n",
    "regr_kf = Pipeline(steps=[('std_sc', StandardScaler()),\n",
    "                       ('mlp', mlpr_kf)])\n",
    "\n",
    "y_transformer = StandardScaler()\n",
    "inner_estimator = TransformedTargetRegressor(regressor=regr_kf,\n",
    "                                             transformer=y_transformer)\n",
    "\n",
    "l_alpha = [10.**k for k in range(-6, 7)]\n",
    "param_grid = {\n",
    "    'regressor__mlp__alpha': l_alpha, \n",
    "    'regressor__mlp__hidden_layer_sizes': [(20,), (20, 20), (20, 20, 20)]    \n",
    "}\n",
    "\n",
    "cv_mlp = GridSearchCV(inner_estimator, \n",
    "                    param_grid=param_grid, \n",
    "                    cv=kf, \n",
    "                    scoring='neg_mean_absolute_error',\n",
    "                    return_train_score=True,\n",
    "                    refit=True,\n",
    "                    n_jobs=-1, \n",
    "                    verbose=1)\n",
    "\n",
    "t_0 = time.time()\n",
    "cv_mlp.fit(x, y)\n",
    "t_1 = time.time() \n",
    "print(\"\\nmlp_grid_search_time: %.2f\" % ((t_1 - t_0)/60.))\n",
    "        \n",
    "# saving alpha_search in a pickle    \n",
    "f_name = 'mlp_search_results_kf.joblib'\n",
    "joblib.dump(cv_mlp, f_name, compress=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing GridSearchCV results\n",
    "\n",
    "In this section the results of the the GridSearchCV are analyzed in function of the mean absolute error (mae). \n",
    "The possible params values are listed below and also, the params which conducted to the model with the lowest error. The alpha selected was 10.00 and (20, 20) as hidden layers size.\n",
    "\n",
    "Check the adequacy of the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_mlp = joblib.load('mlp_search_results_kf.joblib')\n",
    "\n",
    "print(\"alpha_range: %.2f - %.2f\" % (np.array(l_alpha).min(), np.array(l_alpha).max()))\n",
    "print('best_alpha = %.2f' % (cv_mlp.best_params_['regressor__mlp__alpha']))\n",
    "print('----------')\n",
    "\n",
    "print(f\"layer_sizes = {[(20,), (20, 20), (20, 20, 20)]}\" )\n",
    "best_size = cv_mlp.best_params_['regressor__mlp__hidden_layer_sizes']\n",
    "print(f'best_hidden_layer_sizes = {best_size}')\n",
    "print('----------')\n",
    "\n",
    "print(f\"max_iter range: 1000 - 100000\")\n",
    "best_max_iter = cv_mlp.best_params_['regressor__mlp__max_iter']\n",
    "print(f\"best max_iter = {best_max_iter}\")\n",
    "print('----------')\n",
    "\n",
    "print('best_cv_mae = %.3f' % (-cv_mlp.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table below shows the five configurations which reached the highest performance during GridSearch. It can be seen that the best model reached an score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_search = pd.DataFrame.from_dict(cv_mlp.cv_results_)\n",
    "mlp_search.sort_values(by='mean_test_score', ascending=False)[['param_regressor__mlp__alpha',\\\n",
    "                                                                      'param_regressor__mlp__hidden_layer_sizes',\\\n",
    "                                                                      'mean_test_score',\n",
    "                                                                       'mean_train_score']][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following graphic we plot the errors with respect to *alpha*. It can be seen that while the higher the alpha, also increments the absolute error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title('C_vs_mae')\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('cv mae')\n",
    "plt.xscale('log')\n",
    "_ = plt.plot(mlp_search['param_regressor__mlp__alpha'], -mlp_search['mean_test_score'], '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.xticks(range(len(l_alpha)), l_alpha, rotation=45)\n",
    "# _ = plt.plot(-cv_mlp.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the MLPR model\n",
    "\n",
    "Do it over the entire dataset using `cross_val_predict`, get the CV MAE and draw the appropriate plots.\n",
    "\n",
    "We test the model over the entire dataset using the function `cross_val_predict`. In addtion, we plot the predicted and the real values and calculate the MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mlp_cv = np.clip(cross_val_predict(cv_mlp.best_estimator_, x, y, cv=kf, n_jobs=-1), 0., 200.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure( figsize=(8,6))\n",
    "\n",
    "plt.title('Real vs CV Predicted Values')\n",
    "plt.xlabel('wind_energy')\n",
    "plt.ylabel('wind_energy_CV_predicted')\n",
    "_ = plt.plot(y, y_pred_mlp_cv, '.', y, y, '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "print(\"MAE: %.3f\" % mean_absolute_error(y, y_pred_mlp_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Residual histograms and relationship with targets\n",
    "\n",
    "Show and discuss them.\n",
    "\n",
    "In this section we show two graphics related to the model errors. In the first one we show the error distribution and in the second one the real values agains the erros in each of the observation in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = y - y_pred_mlp_cv\n",
    "\n",
    "print(\"mae: %.3f\" % (abs(err).mean()) )\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"CV Error histogram\")\n",
    "plt.xlabel(\"Errs\")\n",
    "plt.ylabel(\"Err frequencies\")\n",
    "_ = plt.hist(err, bins=31)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"CV Error evolution\")\n",
    "plt.xlabel(\"wind_energy\")\n",
    "plt.ylabel(\"Errs\")\n",
    "_ = plt.plot(y, err, '*', y, 0.*y, '-')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first graphic shows that errors have mean close to cero, but they do not look normally distributed. There are more observations with positive error than negative which means that in most of the cases the predicted value is below the real one. This translated to natural language, means that most of the time the model predicts greater wind energy thet the real one. On the other hand, the second graphic shows that the model is more exact in values close to the media, however, in extremes values, high or small, the model gets a greater error, which means that the model gets wrong in high and small wind ebergy values. This figure also shows that there are more points above the zero line than below, confirming what express the histogram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SV Regressor\n",
    "\n",
    "This section is dedicated to the SV Regressor. We will be training a SV regresors with gaussian kernels, reason why we have to set hyperparameters `C, gamma` and the `epsilon` insensitivity. We perform a GridSearchCV to find the parameters which best fit models. As we are going to optimize three values, the search space increases considerably so we need to downsample the original data to values every three hours, making the dataset smaller.\n",
    "\n",
    "In the next output we show a sample of the reduced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = df.resample('3H').first()\n",
    "sample_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reducing, the new dataset have 2193 observations with the same 6 variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sample = sample_df[l_vars].values\n",
    "y_sample = sample_df[['target']].values.reshape(-1,)\n",
    "num_patterns, dim = x_sample.shape\n",
    "num_patterns, dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_C     = [10.**k for k in range(-3, 4)] \n",
    "l_gamma = list( np.array([2.**k for k in range(-2, 7)]) / dim)\n",
    "l_epsilon = [2.**k for k in range(-6, 0)]\n",
    "\n",
    "param_grid ={'regressor__svr__C': l_C,\n",
    "             'regressor__svr__gamma': l_gamma,\n",
    "             'regressor__svr__epsilon': l_epsilon}\n",
    "\n",
    "print(\"num_hyperparams\", len(l_C) * len(l_gamma) * len(l_epsilon))\n",
    "\n",
    "mm_sc = MinMaxScaler()\n",
    "svr = SVR(kernel='rbf', \n",
    "          shrinking=False, \n",
    "          tol=1.e-3)\n",
    "\n",
    "regr = Pipeline(steps=[('minmax_sc', MinMaxScaler()),\n",
    "                       ('svr', svr)])\n",
    "\n",
    "y_transformer = StandardScaler()\n",
    "inner_estimator = TransformedTargetRegressor(regressor=regr,\n",
    "                                             transformer=y_transformer)\n",
    "\n",
    "sv = GridSearchCV(inner_estimator, \n",
    "                    param_grid=param_grid, \n",
    "                    cv=kf, \n",
    "                    scoring='neg_mean_absolute_error', \n",
    "                    refit=True,\n",
    "                    n_jobs=-1,\n",
    "                    return_train_score=True,\n",
    "                    verbose=1)\n",
    "\n",
    "t_0 = time.time()\n",
    "sv.fit(x_sample, y_sample)\n",
    "print(\"grid_search_time: %f segundos\" % (time.time() - t_0))\n",
    "\n",
    "f_pkl = open(\"sv_search_results.pkz\", 'wb') \n",
    "pickle.dump(sv, f_pkl)\n",
    "f_pkl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_pkl = open(\"sv_search_results.pkz\", 'rb') \n",
    "sv = pickle.load(f_pkl)\n",
    "f_pkl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the considered values of selected hyperparams are listed and also, the ones which got the best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"C_range: %.4f - %.0f\" % (np.array(l_C).min(), np.array(l_C).max()))\n",
    "print(\"\\tbest_C:\", sv.best_params_['regressor__svr__C']) \n",
    "print('--------')\n",
    "\n",
    "print(\"gamma_range: %.5f - %.5f\" % (np.array(l_gamma).min(), np.array(l_gamma).max()))\n",
    "print(\"\\tbest_gamma:\", sv.best_params_['regressor__svr__gamma'])\n",
    "print('--------')\n",
    "\n",
    "print(\"epsilon_range: %.5f - %.3f\" % (np.array(l_epsilon).min(), np.array(l_epsilon).max()))\n",
    "print(\"\\tbest_epsilon:\", sv.best_params_['regressor__svr__epsilon'])\n",
    "print('--------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table below shows the the five configurations with the lower error sorted by performance. As we can see the best configuation reached a mae ove of ... over the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_C_gamma_epsilon_search = pd.DataFrame.from_dict(sv.cv_results_)\n",
    "df_C_gamma_epsilon_search.sort_values(by='mean_test_score', ascending=False)[['param_regressor__svr__C',\\\n",
    "                                                                      'param_regressor__svr__gamma',\\\n",
    "                                                                      'param_regressor__svr__epsilon',\\\n",
    "                                                                      'mean_test_score']][ : 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell shows each of the hyperparameter in function of the error reached during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title('C_vs_mae')\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('cv mae')\n",
    "plt.xscale('log')\n",
    "#plt.ylim(1.8, 2.2)\n",
    "_ = plt.plot( df_C_gamma_epsilon_search['param_regressor__svr__C'], -df_C_gamma_epsilon_search['mean_test_score'], '.')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title('gamma_vs_mae')\n",
    "plt.xlabel('gamma')\n",
    "plt.ylabel('cv mae')\n",
    "plt.xscale('log')\n",
    "_ = plt.plot( df_C_gamma_epsilon_search['param_regressor__svr__gamma'], -df_C_gamma_epsilon_search['mean_test_score'], '.')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title('epsilon_vs_mae')\n",
    "plt.xlabel('epsilon')\n",
    "plt.ylabel('cv mae')\n",
    "plt.xscale('log')\n",
    "_ = plt.plot( df_C_gamma_epsilon_search['param_regressor__svr__epsilon'], -df_C_gamma_epsilon_search['mean_test_score'], '.')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first figure shows the `C` in functions of the error reached during training. It can be seen that ....#TODO. The second one shows the `gamma` against the error. This parametars is useful to ...#TODO. On the other hand the third graphic which shows the parameter `epsilon` suggests that this parameter does not has a great incfluence on model results because the mae do not shows great changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator = sv.best_estimator_\n",
    "\n",
    "scores = cross_val_score(best_estimator, x_sample, y_sample, scoring=\"neg_mean_absolute_error\", cv=kf, n_jobs=2)\n",
    "\n",
    "print(\"mae_mean: %.3f\\t\\tmae_std: %.3f\" % (-scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_pred_svr = np.clip(cross_val_predict(best_estimator, x_sample, y_sample, cv=kf, n_jobs=-1), 0., 200.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize=(8,6))\n",
    "\n",
    "plt.title('SVR Real vs CV Predicted Values')\n",
    "plt.xlabel('wind_energy')\n",
    "plt.ylabel('wind_energy_CV_predicted')\n",
    "_ = plt.plot(y_sample, y_pred_svr, '.', y_sample, y_sample, '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = y_sample - y_pred_svr\n",
    "\n",
    "plt.figure( figsize=(16,6))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"CV Error histogram\")\n",
    "plt.xlabel(\"Errs\")\n",
    "plt.ylabel(\"Err frequencies\")\n",
    "_ = plt.hist(err, bins=31)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"CV Error evolution\")\n",
    "plt.xlabel(\"wind_energy\")\n",
    "plt.ylabel(\"Errs\")\n",
    "_ = plt.plot(y, err, '*', y, 0.*y, '-')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLPR and SVR comparison\n",
    "\n",
    "Compare them and draw the appropriate conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mlpr_mae: {0:.3f}\".format(mean_absolute_error(y, y_pred_mlp_cv)))\n",
    "print(\"svr_mae: {0:.3f}\".format(mean_absolute_error(y_sample, y_pred_svr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('MLP Real vs CV Predicted Values')\n",
    "plt.xlabel('wind_energy')\n",
    "plt.ylabel('wind_energy_predicted')\n",
    "_ = plt.plot(y, y_pred_mlp_cv, '.', y, y, '-')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('SVR Real vs CV Predicted Values')\n",
    "plt.xlabel('wind_energy')\n",
    "plt.ylabel('wind_energy_predicted')\n",
    "_ = plt.plot(y_sample, y_pred_svr, '.', y_sample, y_sample, '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize=(16, 12))\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title(\"MLPR Error histogram\")\n",
    "plt.xlabel(\"Errs\")\n",
    "plt.ylabel(\"Err frequencies\")\n",
    "plt.xlim(-80, 80)\n",
    "plt.ylim(0, 1400)\n",
    "_ = plt.hist(y - y_pred_mlp_cv, bins=31)\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.title(\"SVR Error histogram\")\n",
    "plt.xlabel(\"Errs\")\n",
    "plt.ylabel(\"Err frequencies\")\n",
    "plt.xlim(-80, 80)\n",
    "plt.ylim(0, 1400)\n",
    "_ = plt.hist(y_sample - y_pred_svr, bins=31)\n",
    "\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.title(\"MLPR Error evolution\")\n",
    "plt.xlabel(\"wind_energy\")\n",
    "plt.ylabel(\"Errs\")\n",
    "plt.ylim(-100, 100)\n",
    "_ = plt.plot(y, y - y_pred_mlp_cv, '*', y, 0.*y, '-')\n",
    "\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.title(\"SVR Error evolution\")\n",
    "plt.xlabel(\"wind_energy\")\n",
    "plt.ylabel(\"Errs\")\n",
    "plt.ylim(-100, 100)\n",
    "_ = plt.plot(y_sample, y_sample - y_pred_svr, '*', y, 0.*y, '-')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to improve the estimator\n",
    "\n",
    "Me may try to improve the MLPR and SVR results by enlarging the features set with the square and cube powers of the absolute velocities.\n",
    "\n",
    "Redo the previous MLPR and SVR analysis and conclusions over the enlarged dataset with the same analysis structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "square_abs_vel_10 = df[['v10']]**2\n",
    "square_abs_vel_100 = df[['v100']]**2\n",
    "cube_abs_vel_10 = df[['v10']]**2\n",
    "cube_abs_vel_100 = df[['v100']]**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_large = df\n",
    "df_large[['sqr_v10']] = square_abs_vel_10\n",
    "df_large[['sqr_v100']] = square_abs_vel_100\n",
    "df_large[['cub_v10']] = cube_abs_vel_10\n",
    "df_large[['cub_v100']] = cube_abs_vel_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_large.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_large = df_large[list(l_vars) + ['sqr_v10', 'sqr_v100', 'cub_v10', 'sqr_v100']]\n",
    "y_large = df_large[['target']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLPR model over enlarged features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select alpha in mlp regression by CV\n",
    "n_folds = 3\n",
    "kf = KFold(n_folds, shuffle=False)\n",
    "\n",
    "mlpr =  MLPRegressor(activation='relu', \n",
    "                     solver='lbfgs', \n",
    "                     early_stopping=True,\n",
    "                     tol=1.e-3, \n",
    "                     max_iter=10000)\n",
    "\n",
    "regr = Pipeline(steps=[('std_sc', StandardScaler()),\n",
    "                       ('mlp', mlpr)])\n",
    "\n",
    "y_transformer = StandardScaler()\n",
    "inner_estimator = TransformedTargetRegressor(regressor=regr,\n",
    "                                             transformer=y_transformer)\n",
    "\n",
    "l_alpha = [10.**k for k in range(-6, 7)]\n",
    "param_grid = {'regressor__mlp__alpha': l_alpha,\n",
    "             'regressor__mlp__hidden_layer_sizes': [(20,), (20, 20), (20, 20, 20)]}  \n",
    "\n",
    "\n",
    "cv_estimator = GridSearchCV(inner_estimator, \n",
    "                            param_grid=param_grid, \n",
    "                            cv=kf, \n",
    "                            scoring='neg_mean_absolute_error',\n",
    "                            return_train_score=True,\n",
    "                            refit=True,\n",
    "                            n_jobs=-1, \n",
    "                            verbose=1)\n",
    "\n",
    "t_0 = time.time()\n",
    "cv_estimator.fit(x_large, y_large)\n",
    "t_1 = time.time() \n",
    "print(\"\\nmlp_grid_search_time: %.2f\" % ((t_1 - t_0)/60.))\n",
    "        \n",
    "# saving alpha_search in a pickle    \n",
    "f_name = 'mlp_large_search_results.joblib'\n",
    "joblib.dump(cv_estimator, f_name, compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_estimator = joblib.load('mlp_large_search_results.joblib')\n",
    "\n",
    "print(\"alpha_range: %.2f - %.2f\" % (np.array(l_alpha).min(), np.array(l_alpha).max()))\n",
    "print('best_alpha = %.2f' % (cv_estimator.best_params_['regressor__mlp__alpha']))\n",
    "print('----------')\n",
    "\n",
    "print(f\"layer_sizes = {[(20,), (20, 20), (20, 20, 20)]}\" )\n",
    "best_size = cv_estimator.best_params_['regressor__mlp__hidden_layer_sizes']\n",
    "print(f'best_hidden_layer_sizes = {best_size}')\n",
    "print('----------')\n",
    "\n",
    "print('best_cv_mae = %.3f' % (-cv_estimator.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_search = pd.DataFrame.from_dict(cv_estimator.cv_results_)\n",
    "sv_search.sort_values(by='mean_test_score', ascending=False)[['param_regressor__mlp__alpha',\\\n",
    "                                                                      'param_regressor__mlp__hidden_layer_sizes',\\\n",
    "                                                                      'mean_test_score',\n",
    "                                                                       'mean_train_score']][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.xticks(range(len(l_alpha)), l_alpha, rotation=45)\n",
    "# _ = plt.plot( -cv_estimator.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title('C_vs_mae')\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('cv mae')\n",
    "plt.xscale('log')\n",
    "_ = plt.plot(sv_search['param_regressor__mlp__alpha'], -sv_search['mean_test_score'], '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_large_pred_mlp_cv = np.clip( cross_val_predict(cv_estimator.best_estimator_, x_large, y_large, cv=kf, n_jobs=-1), 0., 200.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize=(8,6))\n",
    "\n",
    "plt.title('Real vs CV Predicted Values')\n",
    "plt.xlabel('wind_energy')\n",
    "plt.ylabel('wind_energy_CV_predicted')\n",
    "_ = plt.plot(y_large, y_large_pred_mlp_cv, '.', y_large, y_large, '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = y_large - y_large_pred_mlp_cv\n",
    "\n",
    "print(\"mae: %.3f\" % (abs(err).mean()) )\n",
    "\n",
    "plt.figure( figsize=(16,6))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"CV Error histogram\")\n",
    "plt.xlabel(\"Errs\")\n",
    "plt.ylabel(\"Err frequencies\")\n",
    "_ = plt.hist(err, bins=31)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"CV Error evolution\")\n",
    "plt.xlabel(\"wind_energy\")\n",
    "plt.ylabel(\"Errs\")\n",
    "_ = plt.plot(y_large, err, '*', y_large, 0.*y_large, '-')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions on the enlarged MLPR model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR model over enlarged features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_large_sample = df_large.resample('3H').first()\n",
    "df_large_sample.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_vars_lg = list(l_vars) + ['sqr_v10', 'sqr_v100', 'cub_v10', 'sqr_v100']\n",
    "x_large_sample = df_large_sample[l_vars_lg].values\n",
    "y_large_sample = df_large_sample[['target']].values.reshape(-1,)\n",
    "num_patterns, dim = x_large_sample.shape\n",
    "num_patterns, dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_C     = [10.**k for k in range(-3, 4)] \n",
    "l_gamma = list( np.array([2.**k for k in range(-2, 7)]) / dim)\n",
    "l_epsilon = [2.**k for k in range(-6, 0)]\n",
    "\n",
    "param_grid ={'regressor__svr__C': l_C,\n",
    "             'regressor__svr__gamma': l_gamma,\n",
    "             'regressor__svr__epsilon': l_epsilon}\n",
    "\n",
    "print(\"num_hyperparams\", len(l_C) * len(l_gamma) * len(l_epsilon))\n",
    "\n",
    "mm_sc = MinMaxScaler()\n",
    "svr = SVR(kernel='rbf', \n",
    "          shrinking=False, \n",
    "          tol=1.e-3)\n",
    "\n",
    "regr = Pipeline(steps=[('minmax_sc', MinMaxScaler()),\n",
    "                       ('svr', svr)])\n",
    "\n",
    "y_transformer = StandardScaler()\n",
    "inner_estimator = TransformedTargetRegressor(regressor=regr,\n",
    "                                             transformer=y_transformer)\n",
    "\n",
    "cv_estimator = GridSearchCV(inner_estimator, \n",
    "                            param_grid=param_grid, \n",
    "                            cv=kf, \n",
    "                            scoring='neg_mean_absolute_error', \n",
    "                            refit=True,\n",
    "                            n_jobs=-1,\n",
    "                            return_train_score=True,\n",
    "                            verbose=1)\n",
    "\n",
    "t_0 = time.time()\n",
    "cv_estimator.fit(x_large_sample, y_large_sample)\n",
    "print(\"grid_search_time: %f segundos\" % (time.time() - t_0))\n",
    "\n",
    "f_pkl = open(\"c_gamma_epsilon_cv_search_energy_wind_large.pkz\", 'wb') \n",
    "pickle.dump(cv_estimator, f_pkl)\n",
    "f_pkl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_pkl = open(\"c_gamma_epsilon_cv_search_energy_wind_large.pkz\", 'rb') \n",
    "cv_estimator = pickle.load(f_pkl)\n",
    "f_pkl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"C_range: %.4f - %.0f\" % (np.array(l_C).min(), np.array(l_C).max()))\n",
    "print(\"\\tbest_C:\", cv_estimator.best_params_['regressor__svr__C']) \n",
    "\n",
    "print(\"gamma_range: %.5f - %.5f\" % (np.array(l_gamma).min(), np.array(l_gamma).max()))\n",
    "print(\"\\tbest_gamma:\", cv_estimator.best_params_['regressor__svr__gamma'])\n",
    "\n",
    "print(\"epsilon_range: %.5f - %.3f\" % (np.array(l_epsilon).min(), np.array(l_epsilon).max()))\n",
    "print(\"\\tbest_epsilon:\", cv_estimator.best_params_['regressor__svr__epsilon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_C_gamma_epsilon_search = pd.DataFrame.from_dict(cv_estimator.cv_results_)\n",
    "df_C_gamma_epsilon_search.sort_values(by='mean_test_score', ascending=False)[['param_regressor__svr__C',\\\n",
    "                                                                      'param_regressor__svr__gamma',\\\n",
    "                                                                      'param_regressor__svr__epsilon',\\\n",
    "                                                                      'mean_test_score']][ : 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title('C_vs_mae')\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('cv mae')\n",
    "plt.xscale('log')\n",
    "#plt.ylim(1.8, 2.2)\n",
    "_ = plt.plot( df_C_gamma_epsilon_search['param_regressor__svr__C'], -df_C_gamma_epsilon_search['mean_test_score'], '.')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title('gamma_vs_mae')\n",
    "plt.xlabel('gamma')\n",
    "plt.ylabel('cv mae')\n",
    "plt.xscale('log')\n",
    "_ = plt.plot( df_C_gamma_epsilon_search['param_regressor__svr__gamma'], -df_C_gamma_epsilon_search['mean_test_score'], '.')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title('epsilon_vs_mae')\n",
    "plt.xlabel('epsilon')\n",
    "plt.ylabel('cv mae')\n",
    "plt.xscale('log')\n",
    "_ = plt.plot( df_C_gamma_epsilon_search['param_regressor__svr__epsilon'], -df_C_gamma_epsilon_search['mean_test_score'], '.')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator = cv_estimator.best_estimator_\n",
    "\n",
    "scores = cross_val_score(best_estimator, x_large_sample,y_large_sample, scoring=\"neg_mean_absolute_error\", cv=kf, n_jobs=-1)\n",
    "\n",
    "print(\"mae_mean: %.3f\\t\\tmae_std: %.3f\" % (-scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_large_pred_svr = np.clip( cross_val_predict(best_estimator,  x_large_sample, y_large_sample, cv=kf, n_jobs=-1), 0., 200.)\n",
    "\n",
    "print(\"mae: {0:.3f}\".format(mean_absolute_error( y_large_sample, y_large_pred_svr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize=(8,6))\n",
    "\n",
    "plt.title('SVR Real vs CV Predicted Values')\n",
    "plt.xlabel('wind_energy')\n",
    "plt.ylabel('wind_energy_CV_predicted')\n",
    "_ = plt.plot( y_large_sample, y_large_pred_svr, '.', y_large_sample, y_large_sample, '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err =  y_large_sample - y_large_pred_svr\n",
    "\n",
    "plt.figure( figsize=(16,6))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"CV Error histogram\")\n",
    "plt.xlabel(\"Errs\")\n",
    "plt.ylabel(\"Err frequencies\")\n",
    "_ = plt.hist(err, bins=31)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"CV Error evolution\")\n",
    "plt.xlabel(\"wind_energy\")\n",
    "plt.ylabel(\"Errs\")\n",
    "_ = plt.plot(y_large_sample, err, '*', y_large_sample, 0.*y_large_sample, '-')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mlpr_mae: {0:.3f}\".format(mean_absolute_error(y_large, y_large_pred_mlp_cv)))\n",
    "print(\"svr_mae: {0:.3f}\".format(mean_absolute_error( y_large_sample, y_large_pred_svr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize=(18,6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('SVR Real vs CV Predicted Values')\n",
    "plt.xlabel('wind_energy')\n",
    "plt.ylabel('wind_energy_CV_predicted')\n",
    "_ = plt.plot(y_large_sample, y_large_pred_svr, '.', y_large_sample, y_large_sample, '-')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('MLP Real vs CV Predicted Values')\n",
    "plt.xlabel('wind_energy')\n",
    "plt.ylabel('wind_energy_CV_predicted')\n",
    "_ = plt.plot(y_large, y_large_pred_mlp_cv, '.', y_large, y_large, '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize=(16, 12))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.title(\"SVR Error histogram\")\n",
    "plt.xlabel(\"Errs\")\n",
    "plt.ylabel(\"Err frequencies\")\n",
    "plt.xlim(-100, 100)\n",
    "plt.ylim(0, 300)\n",
    "_ = plt.hist(y_large_sample - y_large_pred_svr, bins=31)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title(\"MLPR Error histogram\")\n",
    "plt.xlabel(\"Errs\")\n",
    "plt.ylabel(\"Err frequencies\")\n",
    "plt.xlim(-100, 100)\n",
    "plt.ylim(0, 300)\n",
    "_ = plt.hist(y_large - y_large_pred_mlp_cv, bins=31)\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.title(\"SVR Error evolution\")\n",
    "plt.xlabel(\"wind_energy\")\n",
    "plt.ylabel(\"Errs\")\n",
    "plt.ylim(-100, 100)\n",
    "_ = plt.plot(y_large_sample, y_large_sample - y_large_pred_svr, '*', y_large_sample, 0.*y_large_sample, '-')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.title(\"MLPR Error evolution\")\n",
    "plt.xlabel(\"wind_energy\")\n",
    "plt.ylabel(\"Errs\")\n",
    "plt.ylim(-100, 100)\n",
    "_ = plt.plot(y_large, y_large - y_large_pred_mlp_cv, '*', y_large, 0.*y_large, '-')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions on the enlarged SVR model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "print(\"\\Total time: %.2f\" % ((end_time - start_time)/60.))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
